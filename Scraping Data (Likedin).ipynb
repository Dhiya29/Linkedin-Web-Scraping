{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIKEDIN WEB SCRAPING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam dunia kerja yang semakin kompetitif, mendapatkan informasi terkini tentang peluang pekerjaan sangatlah penting bagi para pencari kerja dan perusahaan. Salah satu platform yang sering digunakan untuk mencari dan mengiklankan lowongan pekerjaan adalah LinkedIn. Mengingat jumlah data yang sangat besar dan dinamis di LinkedIn, melakukan scraping data menjadi salah satu metode yang efektif untuk mengakses dan mengumpulkan informasi terkait lowongan kerja. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salah satu proses scraping data dari web adalah menggunakan library BeautifulSoup dan Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!pip install chromedriver-autoinstaller\n",
    "!pip install pandas\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BeautifulSoup digunakan untuk parsing HTML dan mengekstrak data yang diinginkan.\n",
    "- selenium adalah alat otomatisasi untuk mengontrol browser secara programatik.\n",
    "- chromedriver_autoinstaller secara otomatis mengunduh dan menginstal ChromeDriver yang kompatibel dengan versi Google Chrome di sistem pengguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the latest chromedriver if necessary\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# configure chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# launch chrome browser\n",
    "browser = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open linkedin job search page\n",
    "#( modify keywords as needed, url below is in one line)\n",
    "browser.get (f'https://www.linkedin.com/jobs/search?keywords=Data%20Analysis&location=Indonesia&geoId=102478259&f_TPR=&f_E=1%2C2&original_referer=https%3A%2F%2Fwww.linkedin.com%2Fjobs%2Fsearch%3Fkeywords%3DData%2520Analysis%26location%3DIndonesia%26geoId%3D102478259%26trk%3Dpublic_jobs_jobs-search-bar_search-submit%26position%3D1%26pageNum%3D0&position=1&pageNum=0')\n",
    "\n",
    "#set the number of pages to scrape\n",
    "pages = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat automasi untuk melakukan scroll dan klik pada tombol \"See more jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n"
     ]
    }
   ],
   "source": [
    "#loop through the specified number of pages to retrieve job postings\n",
    "for i in range(pages):\n",
    "    print(f'Scraping page {i + 1}')\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    try:\n",
    "        #click on the \"see more job\" button if present\n",
    "        element = WebDriverWait(browser, 5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, \"//button[text()='See more jobs']\")\n",
    "            )\n",
    "        )\n",
    "        element.click()\n",
    "    except Exception :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape job postings\n",
    "jobs = []\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "job_listings = soup.find_all(\"div\", class_=\"base-card\")\n",
    "\n",
    "for job in job_listings:\n",
    "    job_title = job.find(\"h3\", class_=\"base-search-card__title\")\n",
    "    job_title = job_title.text.strip() if job_title else \"N/A\"\n",
    "\n",
    "    job_company = job.find(\"h4\", class_=\"base-search-card__subtitle\")\n",
    "    job_company = job_company.text.strip() if job_company else \"N/A\"\n",
    "\n",
    "    job_location = job.find(\"span\", class_=\"job-search-card__location\")\n",
    "    job_location = job_location.text.strip() if job_location else \"N/A\"\n",
    "\n",
    "    job_posting_date = job.find(\"time\", class_=\"job-search-card__listdate\")\n",
    "    job_posting_date = job_posting_date[\"datetime\"] if job_posting_date else \"N/A\"\n",
    "\n",
    "    apply_link = job.find(\"a\", class_=\"base-card__full-link\")\n",
    "    apply_link = apply_link[\"href\"] if apply_link else \"N/A\"\n",
    "    job_ID = apply_link.split('?')[0][-10:] if apply_link != \"N/A\" else \"N/A\"\n",
    "    \n",
    "    #optionally, extract the more description\n",
    "#    try:\n",
    "#        description_soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "#        job_description = description_soup.find_all(\"div\", class_=\"decorated-job-posting__details\")\n",
    "#        job_requirements = description_soup.find(\"div\", class_=\"show-more-less-html__markup relative overflow-hidden\").text.strip()\n",
    "#        job_senioritylevel = description_soup.find(\"span\", class_=\"description__job-criteria-text description__job-criteria-text--criteria\").text.strip()\n",
    "#        job_employmenttype = description_soup.find(\"span\", class_=\"description__job-criteria-text description__job-criteria-text--criteria\").text.strip()\n",
    "#    except AttributeError:\n",
    "#        job_requirements = None\n",
    "#        job_senioritylevel = None\n",
    "#        job_employmenttype = None\n",
    "        \n",
    "    \n",
    "    #optionally, extract the job description\n",
    "  #  try:\n",
    "   #     description_soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "  #      job_description = description_soup.find(\"div\", class_=\"jobs-aplly-button-\").text.strip()\n",
    "  #  except AttributeError:\n",
    "  #      job_description = None\n",
    "    \n",
    "    jobs.append({\n",
    "        \"job ID\": job_ID,\n",
    "        \"posting date\": job_posting_date,\n",
    "        \"title\": job_title,\n",
    "        \"company\": job_company,\n",
    "        \"location\": job_location,\n",
    "        \"link\": apply_link\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job ID</th>\n",
       "      <th>posting date</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3943485503</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>Consumer Insight Analyst</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/consumer-ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3996426597</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>Sustainability Data Analyst</td>\n",
       "      <td>PT Lion Super Indo</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/sustainabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3818183787</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Kalbe Nutritionals Internship</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/kalbe-nutrit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3948515197</td>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>Marketing Internship - PT Kalbe Blackmores Nut...</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/marketing-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3988578383</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>PPIC Internship</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>West Karawang, West Java, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ppic-interns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3959614450</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PT Solomon Indo Global</td>\n",
       "      <td>Greater Surabaya</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3953798332</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>Selection Staff</td>\n",
       "      <td>PT TWO WIN INDONESIA</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/selection-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3994643522</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>Research and Development Supervisor</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>West Karawang, West Java, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/research-and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3956085661</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>Business Operation Specialist</td>\n",
       "      <td>PT. ASTRA DAIHATSU MOTOR</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/business-ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3998476954</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>Shopee &amp; SeaMoney Graduate Development Program...</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/shopee-seamo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        job ID posting date  \\\n",
       "0   3943485503   2024-06-05   \n",
       "1   3996426597   2024-08-12   \n",
       "2   3818183787   2024-02-01   \n",
       "3   3948515197   2024-06-13   \n",
       "4   3988578383   2024-07-31   \n",
       "..         ...          ...   \n",
       "71  3959614450   2024-06-27   \n",
       "72  3953798332   2024-06-20   \n",
       "73  3994643522   2024-08-07   \n",
       "74  3956085661   2024-06-21   \n",
       "75  3998476954   2024-08-15   \n",
       "\n",
       "                                                title  \\\n",
       "0                            Consumer Insight Analyst   \n",
       "1                         Sustainability Data Analyst   \n",
       "2                       Kalbe Nutritionals Internship   \n",
       "3   Marketing Internship - PT Kalbe Blackmores Nut...   \n",
       "4                                     PPIC Internship   \n",
       "..                                                ...   \n",
       "71                                       Data Analyst   \n",
       "72                                    Selection Staff   \n",
       "73                Research and Development Supervisor   \n",
       "74                      Business Operation Specialist   \n",
       "75  Shopee & SeaMoney Graduate Development Program...   \n",
       "\n",
       "                                      company  \\\n",
       "0   Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "1                          PT Lion Super Indo   \n",
       "2   Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "3   Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "4   Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "..                                        ...   \n",
       "71                     PT Solomon Indo Global   \n",
       "72                       PT TWO WIN INDONESIA   \n",
       "73  Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "74                   PT. ASTRA DAIHATSU MOTOR   \n",
       "75                                     Shopee   \n",
       "\n",
       "                               location  \\\n",
       "0           Jakarta, Jakarta, Indonesia   \n",
       "1                    Jakarta, Indonesia   \n",
       "2           Jakarta, Jakarta, Indonesia   \n",
       "3           Jakarta, Jakarta, Indonesia   \n",
       "4   West Karawang, West Java, Indonesia   \n",
       "..                                  ...   \n",
       "71                     Greater Surabaya   \n",
       "72          Jakarta, Jakarta, Indonesia   \n",
       "73  West Karawang, West Java, Indonesia   \n",
       "74          Jakarta, Jakarta, Indonesia   \n",
       "75                   Jakarta, Indonesia   \n",
       "\n",
       "                                                 link  \n",
       "0   https://id.linkedin.com/jobs/view/consumer-ins...  \n",
       "1   https://id.linkedin.com/jobs/view/sustainabili...  \n",
       "2   https://id.linkedin.com/jobs/view/kalbe-nutrit...  \n",
       "3   https://id.linkedin.com/jobs/view/marketing-in...  \n",
       "4   https://id.linkedin.com/jobs/view/ppic-interns...  \n",
       "..                                                ...  \n",
       "71  https://id.linkedin.com/jobs/view/data-analyst...  \n",
       "72  https://id.linkedin.com/jobs/view/selection-st...  \n",
       "73  https://id.linkedin.com/jobs/view/research-and...  \n",
       "74  https://id.linkedin.com/jobs/view/business-ope...  \n",
       "75  https://id.linkedin.com/jobs/view/shopee-seamo...  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make data frame\n",
    "df = pd.DataFrame(jobs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data into a CSV File\n",
    "df = pd.DataFrame(jobs)\n",
    "df.to_csv(\"jobs_data_analyst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
